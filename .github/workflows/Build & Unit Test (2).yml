name: Build & Unit Test

on:
  workflow_call:
    inputs:
      pr_number:
        required: true
        type: string

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
      contents: read
    steps:
      - uses: actions/checkout@v4
      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: "21"
          distribution: "temurin"
          cache: maven

      - name: Build with Maven
        run: mvn -B package -DskipTests
        working-directory: SpringApi

      - name: Run Unit Tests
        id: run_tests
        run: mvn -B test
        working-directory: SpringApi
        continue-on-error: true

      - name: Post PR Comment
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = 'SpringApi/target/surefire-reports';
            let totalUnitTests = 0;
            let totalUnitFailures = 0;
            let totalUnitErrors = 0;
            let totalUnitSkipped = 0;
            let failureDetails = '';

            if (fs.existsSync(path)) {
              const files = fs.readdirSync(path);
              files.forEach(file => {
                if (file.endsWith('.txt')) {
                  const content = fs.readFileSync(`${path}/${file}`, 'utf8');
                  const match = content.match(/Tests run: (\d+), Failures: (\d+), Errors: (\d+), Skipped: (\d+)/);
                  if (match) {
                    totalUnitTests += parseInt(match[1]);
                    totalUnitFailures += parseInt(match[2]);
                    totalUnitErrors += parseInt(match[3]);
                    totalUnitSkipped += parseInt(match[4]);
                    
                    if (parseInt(match[2]) > 0 || parseInt(match[3]) > 0) {
                      // Strip execution time so subsequent runs can be compared accurately
                      const cleanContent = content.replace(/[,]?\s*Time elapsed: [\d.]+\s*s/g, '').trim();
                      failureDetails += `\n**${file}**\n\`\`\`\n${cleanContent}\n\`\`\`\n`;
                    }
                  }
                }
              });
            }

            const success = totalUnitFailures === 0 && totalUnitErrors === 0 && totalUnitTests > 0;
            const statusEmoji = success ? 'âœ…' : 'âŒ';
            const statusText = success ? 'All unit tests passed!' : 'Unit tests failed!';

            const toolIdentifier = '<!-- tool: Unit Tests -->';
            let message = `${toolIdentifier}\n### ${statusEmoji} Unit Test Results: ${statusText}\n\n`;
            message += `| Metric | Count | Emoji |\n`;
            message += `| :--- | :--- | :--- |\n`;
            message += `| **Total Tests** | ${totalUnitTests} | ğŸƒ |\n`;
            message += `| **Passed** | ${totalUnitTests - totalUnitFailures - totalUnitErrors - totalUnitSkipped} | âœ… |\n`;
            message += `| **Failures** | ${totalUnitFailures} | âŒ |\n`;
            message += `| **Errors** | ${totalUnitErrors} | âš ï¸ |\n`;
            message += `| **Skipped** | ${totalUnitSkipped} | â­ï¸ |\n\n`;

            if (!success && failureDetails) {
              message += `#### ğŸ” Failure Details\n<details>\n<summary>Click to expand</summary>\n${failureDetails}\n</details>\n\n`;
            } else if (success) {
              message += `Great job! All ${totalUnitTests} tests are green! ğŸŒŸâœ¨\n\n`;
            }

            if (totalUnitTests === 0) {
              message = `${toolIdentifier}\nâš ï¸ **No unit tests were found or ran.** Please check the build logs.`;
            }

            const prNumber = parseInt('${{ inputs.pr_number }}');

            // Search all pages of PR comments for an existing bot comment
            let page = 1;
            let existingComment = null;
            while (true) {
              const { data: comments } = await github.rest.issues.listComments({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                per_page: 100,
                page: page
              });
              if (comments.length === 0) break;
              const found = comments.find(c => c.body && c.body.includes(toolIdentifier));
              if (found) { existingComment = found; break; }
              if (comments.length < 100) break;
              page++;
            }

            if (existingComment) {
              if (existingComment.body === message) {
                // Identical content â€” do nothing
                console.log("Results unchanged. Skipping comment.");
              } else {
                // Results changed â€” post a reply that quotes the updated summary
                console.log("Results changed. Posting reply with updated results.");
                const replyBody = `> ğŸ”„ **Updated Unit Test Results**\n\n${message}`;
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: prNumber,
                  body: replyBody
                });
                // Also silently update the original so next run compares against the latest state
                await github.rest.issues.updateComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  comment_id: existingComment.id,
                  body: message
                });
              }
            } else {
              // First run â€” create the initial top-level comment
              console.log("No existing comment found. Creating initial comment.");
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body: message
              });
            }

            if (!success) {
              core.setFailed('Unit tests failed. Failing the build.');
            }
